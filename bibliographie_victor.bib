
@inproceedings{schulz_transfer_2018,
	address = {Tokyo, Japan},
	title = {Transfer {Learning} of {Complex} {Motor} {Skills} on the {Humanoid} {Robot} {Affetto}},
	isbn = {978-1-5386-6110-9},
	url = {https://ieeexplore.ieee.org/document/8761031/},
	doi = {10.1109/DEVLRN.2018.8761031},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {2018 {Joint} {IEEE} 8th {International} {Conference} on {Development} and {Learning} and {Epigenetic} {Robotics} ({ICDL}-{EpiRob})},
	publisher = {IEEE},
	author = {Schulz, Alexander and Ishihara, Hisashi and Asada, Minoru and Queisser, Jeffrey Frederic},
	month = sep,
	year = {2018},
	pages = {72--77},
	file = {Schulz et al_2018_Transfer Learning of Complex Motor Skills on the Humanoid Robot Affetto.pdf:/Users/victorparedes/Zotero/storage/QEWDAYNE/Schulz et al_2018_Transfer Learning of Complex Motor Skills on the Humanoid Robot Affetto.pdf:application/pdf}
}

@article{cote-allard_deep_2019,
	title = {Deep {Learning} for {Electromyographic} {Hand} {Gesture} {Signal} {Classification} {Using} {Transfer} {Learning}},
	url = {http://arxiv.org/abs/1801.07756},
	abstract = {In recent years, deep learning algorithms have become increasingly more prominent for their unparalleled ability to automatically learn discriminant features from large amounts of data. However, within the ﬁeld of electromyographybased gesture recognition, deep learning algorithms are seldom employed as they require an unreasonable amount of effort from a single person, to generate tens of thousands of examples.},
	language = {en},
	urldate = {2020-10-13},
	journal = {arXiv:1801.07756 [cs, stat]},
	author = {Côté-Allard, Ulysse and Fall, Cheikh Latyr and Drouin, Alexandre and Campeau-Lecours, Alexandre and Gosselin, Clément and Glette, Kyrre and Laviolette, François and Gosselin, Benoit},
	month = jan,
	year = {2019},
	note = {arXiv: 1801.07756},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Côté-Allard et al_2019_Deep Learning for Electromyographic Hand Gesture Signal Classification Using.pdf:/Users/victorparedes/Zotero/storage/KTNA7CPG/Côté-Allard et al_2019_Deep Learning for Electromyographic Hand Gesture Signal Classification Using.pdf:application/pdf}
}

@article{duan_one-shot_2017,
	title = {One-{Shot} {Imitation} {Learning}},
	url = {http://arxiv.org/abs/1703.07326},
	abstract = {Imitation learning has been commonly applied to solve different tasks in isolation. This usually requires either careful feature engineering, or a signiﬁcant number of samples. This is far from what we desire: ideally, robots should be able to learn from very few demonstrations of any given task, and instantly generalize to new situations of the same task, without requiring task-speciﬁc engineering. In this paper, we propose a meta-learning framework for achieving such capability, which we call one-shot imitation learning.},
	language = {en},
	urldate = {2020-10-13},
	journal = {arXiv:1703.07326 [cs]},
	author = {Duan, Yan and Andrychowicz, Marcin and Stadie, Bradly C. and Ho, Jonathan and Schneider, Jonas and Sutskever, Ilya and Abbeel, Pieter and Zaremba, Wojciech},
	month = dec,
	year = {2017},
	note = {arXiv: 1703.07326},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics},
	file = {Duan et al_2017_One-Shot Imitation Learning.pdf:/Users/victorparedes/Zotero/storage/USXQFGPS/Duan et al_2017_One-Shot Imitation Learning.pdf:application/pdf}
}

@article{finn_model-agnostic_2017,
	title = {Model-{Agnostic} {Meta}-{Learning} for {Fast} {Adaptation} of {Deep} {Networks}},
	url = {http://arxiv.org/abs/1703.03400},
	abstract = {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classiﬁcation, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to ﬁne-tune. We demonstrate that this approach leads to state-of-the-art performance on two fewshot image classiﬁcation benchmarks, produces good results on few-shot regression, and accelerates ﬁne-tuning for policy gradient reinforcement learning with neural network policies.},
	language = {en},
	urldate = {2020-10-13},
	journal = {arXiv:1703.03400 [cs]},
	author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	month = jul,
	year = {2017},
	note = {arXiv: 1703.03400},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {Finn et al_2017_Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.pdf:/Users/victorparedes/Zotero/storage/PS8DI67M/Finn et al_2017_Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.pdf:application/pdf}
}

@article{weiss_survey_2016,
	title = {A survey of transfer learning},
	volume = {3},
	issn = {2196-1115},
	url = {http://journalofbigdata.springeropen.com/articles/10.1186/s40537-016-0043-6},
	doi = {10.1186/s40537-016-0043-6},
	abstract = {Machine learning and data mining techniques have been used in numerous real-world applications. An assumption of traditional machine learning methodologies is the training data and testing data are taken from the same domain, such that the input feature space and data distribution characteristics are the same. However, in some real-world machine learning scenarios, this assumption does not hold. There are cases where training data is expensive or difficult to collect. Therefore, there is a need to create high-performance learners trained with more easily obtained data from different domains. This methodology is referred to as transfer learning. This survey paper formally defines transfer learning, presents information on current solutions, and reviews applications applied to transfer learning. Lastly, there is information listed on software downloads for various transfer learning solutions and a discussion of possible future research work. The transfer learning solutions surveyed are independent of data size and can be applied to big data environments.},
	language = {en},
	number = {1},
	urldate = {2020-10-13},
	journal = {Journal of Big Data},
	author = {Weiss, Karl and Khoshgoftaar, Taghi M. and Wang, DingDing},
	month = dec,
	year = {2016},
	pages = {9},
	file = {Weiss et al_2016_A survey of transfer learning.pdf:/Users/victorparedes/Zotero/storage/FRPC99NS/Weiss et al_2016_A survey of transfer learning.pdf:application/pdf}
}

@inproceedings{sun_meta-transfer_2019,
	title = {Meta-transfer learning for few-shot learning},
	booktitle = {Proceedings of the {IEEE} conference on computer vision and pattern recognition},
	author = {Sun, Qianru and Liu, Yaoyao and Chua, Tat-Seng and Schiele, Bernt},
	year = {2019},
	pages = {403--412}
}

@article{taylor_transfer_2009,
	title = {Transfer learning for reinforcement learning domains: {A} survey.},
	volume = {10},
	number = {7},
	journal = {Journal of Machine Learning Research},
	author = {Taylor, Matthew E and Stone, Peter},
	year = {2009}
}

@article{gui_review_2020,
	title = {A {Review} on {Generative} {Adversarial} {Networks}: {Algorithms}, {Theory}, and {Applications}},
	shorttitle = {A {Review} on {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/2001.06937},
	abstract = {Generative adversarial networks (GANs) are a hot research topic recently. GANs have been widely studied since 2014, and a large number of algorithms have been proposed. However, there is few comprehensive study explaining the connections among different GANs variants, and how they have evolved. In this paper, we attempt to provide a review on various GANs methods from the perspectives of algorithms, theory, and applications. Firstly, the motivations, mathematical representations, and structure of most GANs algorithms are introduced in details. Furthermore, GANs have been combined with other machine learning algorithms for speciﬁc applications, such as semi-supervised learning, transfer learning, and reinforcement learning. This paper compares the commonalities and differences of these GANs methods. Secondly, theoretical issues related to GANs are investigated. Thirdly, typical applications of GANs in image processing and computer vision, natural language processing, music, speech and audio, medical ﬁeld, and data science are illustrated. Finally, the future open research problems for GANs are pointed out.},
	language = {en},
	urldate = {2020-10-13},
	journal = {arXiv:2001.06937 [cs, stat]},
	author = {Gui, Jie and Sun, Zhenan and Wen, Yonggang and Tao, Dacheng and Ye, Jieping},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.06937},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Gui et al_2020_A Review on Generative Adversarial Networks.pdf:/Users/victorparedes/Zotero/storage/QM548ARI/Gui et al_2020_A Review on Generative Adversarial Networks.pdf:application/pdf}
}

@article{tiao_cycle-consistent_2018,
	title = {Cycle-{Consistent} {Adversarial} {Learning} as {Approximate} {Bayesian} {Inference}},
	url = {http://arxiv.org/abs/1806.01771},
	abstract = {We formalize the problem of learning interdomain correspondences in the absence of paired data as Bayesian inference in a latent variable model (LVM), where one seeks the underlying hidden representations of entities from one domain as entities from the other domain. First, we introduce implicit latent variable models, where the prior over hidden representations can be speciﬁed ﬂexibly as an implicit distribution. Next, we develop a new variational inference (VI) algorithm for this model based on minimization of the symmetric Kullback-Leibler (KL) divergence between a variational joint and the exact joint distribution. Lastly, we demonstrate that the state-of-the-art cycle-consistent adversarial learning (CYCLEGAN) models can be derived as a special case within our proposed VI framework, thus establishing its connection to approximate Bayesian inference methods.},
	language = {en},
	urldate = {2020-10-13},
	journal = {arXiv:1806.01771 [cs, stat]},
	author = {Tiao, Louis C. and Bonilla, Edwin V. and Ramos, Fabio},
	month = aug,
	year = {2018},
	note = {arXiv: 1806.01771},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Tiao et al_2018_Cycle-Consistent Adversarial Learning as Approximate Bayesian Inference.pdf:/Users/victorparedes/Zotero/storage/LNHLIL65/Tiao et al_2018_Cycle-Consistent Adversarial Learning as Approximate Bayesian Inference.pdf:application/pdf}
}

@article{calinon_tutorial_2016,
	title = {A tutorial on task-parameterized movement learning and retrieval},
	volume = {9},
	issn = {1861-2776, 1861-2784},
	url = {http://link.springer.com/10.1007/s11370-015-0187-9},
	doi = {10.1007/s11370-015-0187-9},
	abstract = {Task-parameterized models of movements aims at automatically adapting movements to new situations encountered by a robot. The task parameters can for example take the form of positions of objects in the environment, or landmark points that the robot should pass through. This tutorial aims at reviewing existing approaches for task-adaptive motion encoding. It then narrows down the scope to the special case of task parameters that take the form of frames of reference, coordinate systems, or basis functions, which are most commonly encountered in service robotics. Each section of the paper is accompanied with source codes designed as simple didactic examples implemented in Matlab with a full compatibility with GNU Octave, closely following the notation and equations of the article. It also presents ongoing work and further challenges that remain to be addressed, with examples provided in simulation and on a real robot (transfer of manipulation behaviors to the Baxter bimanual robot). The repository for the accompanying source codes is available at http://www.idiap.ch/software/pbdlib/.},
	language = {en},
	number = {1},
	urldate = {2020-10-13},
	journal = {Intelligent Service Robotics},
	author = {Calinon, Sylvain},
	month = jan,
	year = {2016},
	pages = {1--29},
	file = {Calinon_2016_A tutorial on task-parameterized movement learning and retrieval.pdf:/Users/victorparedes/Zotero/storage/929J8YBR/Calinon_2016_A tutorial on task-parameterized movement learning and retrieval.pdf:application/pdf}
}

@article{stergiou_human_2011,
	title = {Human movement variability, nonlinear dynamics, and pathology: {Is} there a connection?},
	volume = {30},
	issn = {01679457},
	shorttitle = {Human movement variability, nonlinear dynamics, and pathology},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167945711000832},
	doi = {10.1016/j.humov.2011.06.002},
	language = {en},
	number = {5},
	urldate = {2020-10-13},
	journal = {Human Movement Science},
	author = {Stergiou, Nicholas and Decker, Leslie M.},
	month = oct,
	year = {2011},
	pages = {869--888},
	file = {Stergiou_Decker_2011_Human movement variability, nonlinear dynamics, and pathology.pdf:/Users/victorparedes/Zotero/storage/7M8MYKUY/Stergiou_Decker_2011_Human movement variability, nonlinear dynamics, and pathology.pdf:application/pdf}
}

@inproceedings{calinon_statistical_2012,
	address = {Osaka, Japan},
	title = {Statistical dynamical systems for skills acquisition in humanoids},
	isbn = {978-1-4673-1369-8},
	url = {http://ieeexplore.ieee.org/document/6651539/},
	doi = {10.1109/HUMANOIDS.2012.6651539},
	abstract = {Learning by imitation in humanoids is challenging due to the unpredictable environments these robots have to face during reproduction. Two sets of tools are relevant for this purpose: 1) probabilistic machine learning methods that can extract and exploit the regularities and important features of the task; and 2) dynamical systems that can cope with perturbation in real-time without having to replan the whole movement. We present a learning by imitation approach combining the two beneﬁts. It is based on a superposition of virtual spring-damper systems to drive a humanoid robot’s movement. The method relies on a statistical description of the springs attractor points acting in different candidate frames of reference. It extends dynamic movement primitives models by formulating the dynamical systems parameters estimation problem as a Gaussian mixture regression problem with projection in different coordinate systems. The robot exploits local variability information extracted from multiple demonstrations of movements to determine which frames are relevant for the task, and how the movement should be modulated with respect to these frames. The approach is tested on the new prototype of the COMAN compliant humanoid with time-based and timeinvariant movements, including bimanual coordination skills.},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {2012 12th {IEEE}-{RAS} {International} {Conference} on {Humanoid} {Robots} ({Humanoids} 2012)},
	publisher = {IEEE},
	author = {Calinon, Sylvain and Li, Zhibin and Alizadeh, Tohid and Tsagarakis, Nikos G. and Caldwell, Darwin G.},
	month = nov,
	year = {2012},
	pages = {323--329},
	file = {Calinon et al_2012_Statistical dynamical systems for skills acquisition in humanoids.pdf:/Users/victorparedes/Zotero/storage/HH6RLPR8/Calinon et al_2012_Statistical dynamical systems for skills acquisition in humanoids.pdf:application/pdf}
}

@article{caramiaux_machine_2020,
	title = {Machine {Learning} {Approaches} {For} {Motor} {Learning}: {A} {Short} {Review}},
	shorttitle = {Machine {Learning} {Approaches} {For} {Motor} {Learning}},
	url = {http://arxiv.org/abs/2002.04317},
	abstract = {The use of machine learning to model motor learning mechanisms is still limited, while it could help to design novel interactive systems for movement learning or rehabilitation. This approach requires to account for the motor variability induced by motor learning mechanisms. This represents speciﬁc challenges concerning fast adaptability of the computational models, from small variations to more drastic changes, including new movement classes. We propose a short review on machine learning based movement models and their existing adaptation mechanisms. We discuss the current challenges for applying these models in motor learning support systems, delineating promising research directions at the intersection of machine learning and motor learning.},
	language = {en},
	urldate = {2020-10-13},
	journal = {arXiv:2002.04317 [cs, stat]},
	author = {Caramiaux, Baptiste and Françoise, Jules and Liu, Wanyu and Sanchez, Téo and Bevilacqua, Frédéric},
	month = jun,
	year = {2020},
	note = {arXiv: 2002.04317},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Computer Science - Robotics, I.2.6, J.4, Statistics - Machine Learning},
	file = {Caramiaux et al_2020_Machine Learning Approaches For Motor Learning.pdf:/Users/victorparedes/Zotero/storage/TXRC6EEL/Caramiaux et al_2020_Machine Learning Approaches For Motor Learning.pdf:application/pdf}
}

@article{scurto_designing_2019,
	title = {Designing {Deep} {Reinforcement} {Learning} for {Human} {Parameter} {Exploration}},
	url = {http://arxiv.org/abs/1907.00824},
	abstract = {Software tools for generating digital sound often present users with high-dimensional, parametric interfaces, that may not facilitate exploration of diverse sound designs. In this paper, we propose to investigate artiﬁcial agents using deep reinforcement learning to explore parameter spaces in partnership with users for sound design. We describe a series of user-centred studies to probe the creative beneﬁts of these agents and adapting their design to exploration. Preliminary studies observing users’ exploration strategies with parametric interfaces and testing different agent exploration behaviours led to the design of a fully-functioning prototype, called Co-Explorer, that we evaluated in a workshop with professional sound designers. We found that the Co-Explorer enables a novel creative workﬂow centred on human-machine partnership, which has been positively received by practitioners. We also highlight varied user exploration behaviors throughout partnering with our system. Finally, we frame design guidelines for enabling such co-exploration workﬂow in creative digital applications.},
	language = {en},
	urldate = {2020-10-13},
	journal = {arXiv:1907.00824 [cs, eess]},
	author = {Scurto, Hugo and Van Kerrebroeck, Bavo and Caramiaux, Baptiste and Bevilacqua, Frédéric},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.00824},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
	file = {Scurto et al_2019_Designing Deep Reinforcement Learning for Human Parameter Exploration.pdf:/Users/victorparedes/Zotero/storage/JJVXFVHM/Scurto et al_2019_Designing Deep Reinforcement Learning for Human Parameter Exploration.pdf:application/pdf}
}

@article{matsubara_learning_2011,
	title = {Learning parametric dynamic movement primitives from multiple demonstrations},
	volume = {24},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608011000566},
	doi = {10.1016/j.neunet.2011.02.004},
	abstract = {Learning from demonstration has shown to be a suitable approach for learning control policies (CPs). However, most previous studies learn CPs from a single demonstration, which results in limited scalability and insufficient generalization toward a wide range of applications in real environments. This paper proposes a novel approach to learn highly scalable CPs of basis movement skills from multiple demonstrations. In contrast to conventional studies with a single demonstration, i.e., dynamic movement primitives (DMPs), our approach efficiently encodes multiple demonstrations by shaping a parametricattractor landscape in a set of differential equations. Assuming a certain similarity among multiple demonstrations, our approach learns the parametric-attractor landscape by extracting a small number of common factors in multiple demonstrations. The learned CPs allow the synthesis of novel movements with novel motion styles by specifying the linear coefficients of the bases as parameter vectors without losing useful properties of the DMPs, such as stability and robustness against perturbations. For both discrete and rhythmic movement skills, we present a unified learning procedure for learning a parametricattractor landscape from multiple demonstrations. The feasibility and highly extended scalability of DMPs are demonstrated on an actual dual-arm robot.},
	language = {en},
	number = {5},
	urldate = {2020-10-13},
	journal = {Neural Networks},
	author = {Matsubara, Takamitsu and Hyon, Sang-Ho and Morimoto, Jun},
	month = jun,
	year = {2011},
	pages = {493--500},
	file = {Matsubara et al_2011_Learning parametric dynamic movement primitives from multiple demonstrations.pdf:/Users/victorparedes/Zotero/storage/572B873T/Matsubara et al_2011_Learning parametric dynamic movement primitives from multiple demonstrations.pdf:application/pdf}
}

@article{holden_deep_2016,
	title = {A deep learning framework for character motion synthesis and editing},
	volume = {35},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/2897824.2925975},
	doi = {10.1145/2897824.2925975},
	abstract = {We present a framework to synthesize character movements based on high level parameters, such that the produced movements respect the manifold of human motion, trained on a large motion capture dataset. The learned motion manifold, which is represented by the hidden units of a convolutional autoencoder, represents motion data in sparse components which can be combined to produce a wide range of complex movements. To map from high level parameters to the motion manifold, we stack a deep feedforward neural network on top of the trained autoencoder. This network is trained to produce realistic motion sequences from parameters such as a curve over the terrain that the character should follow, or a target location for punching and kicking. The feedforward control network and the motion manifold are trained independently, allowing the user to easily switch between feedforward networks according to the desired interface, without re-training the motion manifold. Once motion is generated it can be edited by performing optimization in the space of the motion manifold. This allows for imposing kinematic constraints, or transforming the style of the motion, while ensuring the edited motion remains natural. As a result, the system can produce smooth, high quality motion sequences without any manual pre-processing of the training data.},
	language = {en},
	number = {4},
	urldate = {2020-10-13},
	journal = {ACM Transactions on Graphics},
	author = {Holden, Daniel and Saito, Jun and Komura, Taku},
	month = jul,
	year = {2016},
	pages = {1--11},
	file = {Holden et al_2016_A deep learning framework for character motion synthesis and editing.pdf:/Users/victorparedes/Zotero/storage/WU3NRRNM/Holden et al_2016_A deep learning framework for character motion synthesis and editing.pdf:application/pdf}
}

@article{van_vugt_known_2018,
	title = {From known to unknown: moving to unvisited locations in a novel sensorimotor map: {Moving} to unvisited locations in sensorimotor maps},
	volume = {1423},
	issn = {00778923},
	shorttitle = {From known to unknown},
	url = {http://doi.wiley.com/10.1111/nyas.13608},
	doi = {10.1111/nyas.13608},
	language = {en},
	number = {1},
	urldate = {2020-10-13},
	journal = {Annals of the New York Academy of Sciences},
	author = {van Vugt, Floris T. and Ostry, David J.},
	month = jul,
	year = {2018},
	pages = {368--377},
	file = {van Vugt_Ostry_2018_From known to unknown.pdf:/Users/victorparedes/Zotero/storage/9CYXEQN9/van Vugt_Ostry_2018_From known to unknown.pdf:application/pdf}
}

@article{sidarta_somatosensory_2018,
	title = {Somatosensory working memory in human reinforcement-based motor learning},
	volume = {120},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.00442.2018},
	doi = {10.1152/jn.00442.2018},
	abstract = {Recent studies using visuomotor adaptation and sequence learning tasks have assessed the involvement of working memory in the visuospatial domain. The capacity to maintain previously performed movements in working memory is perhaps even more important in reinforcement-based learning to repeat accurate movements and avoid mistakes. Using this kind of task in the present work, we tested the relationship between somatosensory working memory and motor learning. The first experiment involved separate memory and motor learning tasks. In the memory task, the participant’s arm was displaced in different directions by a robotic arm, and the participant was asked to judge whether a subsequent test direction was one of the previously presented directions. In the motor learning task, participants made reaching movements to a hidden visual target and were provided with positive feedback as reinforcement when the movement ended in the target zone. It was found that participants that had better somatosensory working memory showed greater motor learning. In a second experiment, we designed a new task in which learning and working memory trials were interleaved, allowing us to study participants’ memory for movements they performed as part of learning. As in the first experiment, we found that participants with better somatosensory working memory also learned more. Moreover, memory performance for successful movements was better than for movements that failed to reach the target. These results suggest that somatosensory working memory is involved in reinforcement motor learning and that this memory preferentially keeps track of reinforced movements.
            NEW \& NOTEWORTHY The present work examined somatosensory working memory in reinforcement-based motor learning. Working memory performance was reliably correlated with the extent of learning. With the use of a paradigm in which learning and memory trials were interleaved, memory was assessed for movements performed during learning. Movements that received positive feedback were better remembered than movements that did not. Thus working memory does not track all movements equally but is biased to retain movements that were rewarded.},
	language = {en},
	number = {6},
	urldate = {2020-10-13},
	journal = {Journal of Neurophysiology},
	author = {Sidarta, Ananda and van Vugt, Floris T. and Ostry, David J.},
	month = dec,
	year = {2018},
	pages = {3275--3286},
	file = {Sidarta et al_2018_Somatosensory working memory in human reinforcement-based motor learning.pdf:/Users/victorparedes/Zotero/storage/BQM36SAG/Sidarta et al_2018_Somatosensory working memory in human reinforcement-based motor learning.pdf:application/pdf}
}

@article{van_vugt_structure_2018,
	title = {The {Structure} and {Acquisition} of {Sensorimotor} {Maps}},
	volume = {30},
	issn = {0898-929X, 1530-8898},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/jocn_a_01204},
	doi = {10.1162/jocn_a_01204},
	abstract = {One of the puzzles of learning to talk or play a musical instrument is how we learn which movement produces a particular sound: an audiomotor map. Existing research has used mappings that are already well learned such as controlling a cursor using a computer mouse. By contrast, the acquisition of novel sensorimotor maps was studied by having participants learn arm movements to auditory targets. These sounds did not come from different directions but, like speech, were only distinguished by their frequencies. It is shown that learning involves forming not one but two maps: a point map connecting sensory targets with motor commands and an error map linking sensory errors to motor corrections. Learning a point map is possible even when targets never repeat. Thus, although participants make errors, there is no opportunity to correct them because the target is different on every trial, and therefore learning cannot be driven by error correction. Furthermore, when the opportunity for error correction is provided, it is seen that acquiring error correction is itself a learning process that changes over time and results in an error map. In principle, the error map could be derived from the point map, but instead, these two maps are independently acquired and jointly enable sensorimotor control and learning. A computational model shows that this dual encoding is optimal and simulations based on this architecture predict that learning the two maps results in performance improvements comparable with those observed empirically.},
	language = {en},
	number = {3},
	urldate = {2020-10-13},
	journal = {Journal of Cognitive Neuroscience},
	author = {van Vugt, Floris T. and Ostry, David J.},
	month = mar,
	year = {2018},
	pages = {290--306},
	file = {van Vugt_Ostry_2018_The Structure and Acquisition of Sensorimotor Maps.pdf:/Users/victorparedes/Zotero/storage/9PNFKWK3/van Vugt_Ostry_2018_The Structure and Acquisition of Sensorimotor Maps.pdf:application/pdf}
}

@article{van_vugt_early_2019,
	title = {Early stages of sensorimotor map acquisition: learning with free exploration, without active movement or global structure},
	volume = {122},
	issn = {0022-3077, 1522-1598},
	shorttitle = {Early stages of sensorimotor map acquisition},
	url = {https://www.physiology.org/doi/10.1152/jn.00429.2019},
	doi = {10.1152/jn.00429.2019},
	abstract = {One of the puzzles of learning to talk or play a musical instrument is how we learn which movement produces a particular sound: an audiomotor map. The initial stages of map acquisition can be studied by having participants learn arm movements to auditory targets. The key question is what mechanism drives this early learning. Three learning processes from previous literature were tested: map learning may rely on active motor outflow (target), on error correction, and on the correspondence between sensory and motor distances (i.e., that similar movements map to similar sounds). Alternatively, we hypothesized that map learning can proceed without these. Participants made movements that were mapped to sounds in a number of different conditions that each precluded one of the potential learning processes. We tested whether map learning relies on assumptions about topological continuity by exposing participants to a permuted map that did not preserve distances in auditory and motor space. Further groups were tested who passively experienced the targets, kinematic trajectories produced by a robot arm, and auditory feedback as a yoked active participant (hence without active motor outflow). Another group made movements without receiving targets (thus without experiencing errors). In each case we observed substantial learning, therefore none of the three hypothesized processes is required for learning. Instead early map acquisition can occur with free exploration without target error correction, is based on sensory-to-sensory correspondences, and possible even for discontinuous maps. The findings are consistent with the idea that early sensorimotor map formation can involve instance-specific learning.
            NEW \& NOTEWORTHY This study tested learning of novel sensorimotor maps in a variety of unusual circumstances, including learning a mapping that was permuted in such as way that it fragmented the sensorimotor workspace into discontinuous parts, thus not preserving sensory and motor topology. Participants could learn this mapping, and they could learn without motor outflow or targets. These results point to a robust learning mechanism building on individual instances, inspired from machine learning literature.},
	language = {en},
	number = {4},
	urldate = {2020-10-13},
	journal = {Journal of Neurophysiology},
	author = {van Vugt, F. T. and Ostry, D. J.},
	month = oct,
	year = {2019},
	pages = {1708--1720},
	file = {van Vugt_Ostry_2019_Early stages of sensorimotor map acquisition.pdf:/Users/victorparedes/Zotero/storage/33ITAIVK/van Vugt_Ostry_2019_Early stages of sensorimotor map acquisition.pdf:application/pdf}
}

@article{wu_temporal_2014,
	title = {Temporal structure of motor variability is dynamically regulated and predicts motor learning ability},
	volume = {17},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/nn.3616},
	doi = {10.1038/nn.3616},
	language = {en},
	number = {2},
	urldate = {2020-10-13},
	journal = {Nature Neuroscience},
	author = {Wu, Howard G and Miyamoto, Yohsuke R and Castro, Luis Nicolas Gonzalez and Ölveczky, Bence P and Smith, Maurice A},
	month = feb,
	year = {2014},
	pages = {312--321},
	file = {Wu et al_2014_Temporal structure of motor variability is dynamically regulated and predicts.pdf:/Users/victorparedes/Zotero/storage/ANV42DLW/Wu et al_2014_Temporal structure of motor variability is dynamically regulated and predicts.pdf:application/pdf}
}

@article{braun_motor_2009,
	title = {Motor {Task} {Variation} {Induces} {Structural} {Learning}},
	volume = {19},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982209006083},
	doi = {10.1016/j.cub.2009.01.036},
	abstract = {When we have learned a motor skill, such as cycling or iceskating, we can rapidly generalize to novel tasks, such as motorcycling or rollerblading [1–8]. Such facilitation of learning could arise through two distinct mechanisms by which the motor system might adjust its control parameters. First, fast learning could simply be a consequence of the proximity of the original and ﬁnal settings of the control parameters. Second, by structural learning [9–14], the motor system could constrain the parameter adjustments to conform to the control parameters’ covariance structure. Thus, facilitation of learning would rely on the novel task parameters’ lying on the structure of a lower-dimensional subspace that can be explored more efﬁciently. To test between these two hypotheses, we exposed subjects to randomly varying visuomotor tasks of ﬁxed structure. Although such randomly varying tasks are thought to prevent learning, we show that when subsequently presented with novel tasks, subjects exhibit three key features of structural learning: facilitated learning of tasks with the same structure, strong reduction in interference normally observed when switching between tasks that require opposite control strategies, and preferential exploration along the learned structure. These results suggest that skill generalization relies on task variation and structural learning.},
	language = {en},
	number = {4},
	urldate = {2020-10-13},
	journal = {Current Biology},
	author = {Braun, Daniel A. and Aertsen, Ad and Wolpert, Daniel M. and Mehring, Carsten},
	month = feb,
	year = {2009},
	pages = {352--357},
	file = {Braun et al_2009_Motor Task Variation Induces Structural Learning.pdf:/Users/victorparedes/Zotero/storage/AZRBJVKZ/Braun et al_2009_Motor Task Variation Induces Structural Learning.pdf:application/pdf}
}

@article{sternad_its_2018,
	title = {It's not (only) the mean that matters: variability, noise and exploration in skill learning},
	volume = {20},
	issn = {23521546},
	shorttitle = {It's not (only) the mean that matters},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352154617300864},
	doi = {10.1016/j.cobeha.2018.01.004},
	language = {en},
	urldate = {2020-10-13},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Sternad, Dagmar},
	month = apr,
	year = {2018},
	pages = {183--195},
	file = {Sternad_2018_It's not (only) the mean that matters.pdf:/Users/victorparedes/Zotero/storage/VEMZD6Q2/Sternad_2018_It's not (only) the mean that matters.pdf:application/pdf}
}

@article{he_statistical_2016,
	title = {The {Statistical} {Determinants} of the {Speed} of {Motor} {Learning}},
	volume = {12},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1005023},
	doi = {10.1371/journal.pcbi.1005023},
	language = {en},
	number = {9},
	urldate = {2020-10-13},
	journal = {PLOS Computational Biology},
	author = {He, Kang and Liang, You and Abdollahi, Farnaz and Fisher Bittmann, Moria and Kording, Konrad and Wei, Kunlin},
	editor = {Diedrichsen, Jörn},
	month = sep,
	year = {2016},
	pages = {e1005023},
	file = {He et al_2016_The Statistical Determinants of the Speed of Motor Learning.pdf:/Users/victorparedes/Zotero/storage/D5CLJCS8/He et al_2016_The Statistical Determinants of the Speed of Motor Learning.pdf:application/pdf}
}

@article{dhawale_adaptive_2019,
	title = {Adaptive {Regulation} of {Motor} {Variability}},
	volume = {29},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982219311029},
	doi = {10.1016/j.cub.2019.08.052},
	abstract = {Trial-to-trial movement variability can both drive motor learning and interfere with expert performance, suggesting beneﬁts of regulating it in context-speciﬁc ways. Here we address whether and how the brain regulates motor variability as a function of performance by training rats to execute ballistic forelimb movements for reward. Behavioral datasets comprising millions of trials revealed that motor variability is regulated by two distinct processes. A fast process modulates variability as a function of recent trial outcomes, increasing it when performance is poor and vice versa. A slower process tunes the gain of the fast process based on the uncertainty in the task’s reward landscape. Simulations demonstrated that this regulation strategy optimizes reward accumulation over a wide range of time horizons, while also promoting learning. Our results uncover a sophisticated algorithm implemented by the brain to adaptively regulate motor variability to improve task performance.},
	language = {en},
	number = {21},
	urldate = {2020-10-13},
	journal = {Current Biology},
	author = {Dhawale, Ashesh K. and Miyamoto, Yohsuke R. and Smith, Maurice A. and Ölveczky, Bence P.},
	month = nov,
	year = {2019},
	pages = {3551--3562.e7},
	file = {Dhawale et al_2019_Adaptive Regulation of Motor Variability.pdf:/Users/victorparedes/Zotero/storage/UX3VIF72/Dhawale et al_2019_Adaptive Regulation of Motor Variability.pdf:application/pdf}
}

@article{furuki_decomposing_2019,
	title = {Decomposing motion that changes over time into task-relevant and task-irrelevant components in a data-driven manner: application to motor adaptation in whole-body movements},
	volume = {9},
	issn = {2045-2322},
	shorttitle = {Decomposing motion that changes over time into task-relevant and task-irrelevant components in a data-driven manner},
	url = {http://www.nature.com/articles/s41598-019-43558-z},
	doi = {10.1038/s41598-019-43558-z},
	language = {en},
	number = {1},
	urldate = {2020-10-13},
	journal = {Scientific Reports},
	author = {Furuki, Daisuke and Takiyama, Ken},
	month = dec,
	year = {2019},
	pages = {7246},
	file = {Furuki_Takiyama_2019_Decomposing motion that changes over time into task-relevant and.pdf:/Users/victorparedes/Zotero/storage/7UGA9M32/Furuki_Takiyama_2019_Decomposing motion that changes over time into task-relevant and.pdf:application/pdf}
}

@article{vetter_planning_2002,
	title = {Planning {Movements} in a {Simple} {Redundant} {Task}},
	volume = {12},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982202007157},
	doi = {10.1016/S0960-9822(02)00715-7},
	abstract = {There are infinitely many different combinations of arm postures which will place the hand at the same point in space [1]. Given this abundance, how is one configuration chosen over another? Two main hypotheses have been proposed to solve this problem [2]. Postural models suggest that the posture adopted is purely determined by the desired hand position (known as Donders’ law) [3, 4]. Transport models suggest that the adopted posture depends on where the hand has moved from. A specific transport model, the minimum work model, has been proposed in which the adopted posture is the one that minimizes the amount of work required to move the hand to the new location [5]. The postural model predicts that the posture will be independent of where the hand has moved from, whereas the transport models predict that the posture will depend on the previous posture. We have devised a simple redundant task—touching a target bar using a hand-held virtual stick—to examine these models. The results show that neither model alone can account for the data. We propose a control planning strategy in which there is a combined cost function that has both a postural term as well as a transport term.},
	language = {en},
	number = {6},
	urldate = {2020-10-13},
	journal = {Current Biology},
	author = {Vetter, Philipp and Flash, Tamar and Wolpert, Daniel M.},
	month = mar,
	year = {2002},
	pages = {488--491},
	file = {Vetter et al_2002_Planning Movements in a Simple Redundant Task.pdf:/Users/victorparedes/Zotero/storage/I7I88NQU/Vetter et al_2002_Planning Movements in a Simple Redundant Task.pdf:application/pdf}
}

@article{dhawale_role_2017,
	title = {The {Role} of {Variability} in {Motor} {Learning}},
	volume = {40},
	issn = {0147-006X, 1545-4126},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-neuro-072116-031548},
	doi = {10.1146/annurev-neuro-072116-031548},
	abstract = {Trial-to-trial variability in the execution of movements and motor skills is ubiquitous and widely considered to be the unwanted consequence of a noisy nervous system. However, recent studies have suggested that motor variability may also be a feature of how sensorimotor systems operate and learn. This view, rooted in reinforcement learning theory, equates motor variability with purposeful exploration of motor space that, when coupled with reinforcement, can drive motor learning. Here we review studies that explore the relationship between motor variability and motor learning in both humans and animal models. We discuss neural circuit mechanisms that underlie the generation and regulation of motor variability and consider the implications that this work has for our understanding of motor learning.},
	language = {en},
	number = {1},
	urldate = {2020-10-13},
	journal = {Annual Review of Neuroscience},
	author = {Dhawale, Ashesh K. and Smith, Maurice A. and Ölveczky, Bence P.},
	month = jul,
	year = {2017},
	pages = {479--498},
	file = {Dhawale et al_2017_The Role of Variability in Motor Learning.pdf:/Users/victorparedes/Zotero/storage/T23GJFRE/Dhawale et al_2017_The Role of Variability in Motor Learning.pdf:application/pdf}
}

@article{therrien_increasing_2018,
	title = {Increasing {Motor} {Noise} {Impairs} {Reinforcement} {Learning} in {Healthy} {Individuals}},
	volume = {5},
	issn = {2373-2822},
	url = {http://eneuro.org/lookup/doi/10.1523/ENEURO.0050-18.2018},
	doi = {10.1523/ENEURO.0050-18.2018},
	abstract = {Motor variability from exploration is crucial for reinforcement learning as it allows the nervous system to find new task solutions. However, motor variability from noise can be detrimental to learning and may underlie slowed reinforcement learning performance observed in individuals with cerebellar damage. Here we examine whether artificially increasing noise in healthy individuals slows reinforcement learning in a manner similar to that seen in patients with cerebellar damage. Participants used binary reinforcement to learn to rotate their reach angle in a series of directions. By comparing task performance between conditions with different levels of added noise, we show that adding a high level of noise—matched to a group of patients with cerebellar damage—slows learning. In additional experiments, we show that the detrimental effect of noise may lie in reinforcing incorrect behavior, rather than not reinforcing correct behavior. By comparing performance between healthy participants with added noise and a group of patients with cerebellar damage, we found that added noise does not slow the learning of the control group to the same degree observed in the patient group. Using a mechanistic model, we show that added noise in the present study matched patients’ motor noise and total learning. However, increased exploration in the control group relative to the group with cerebellar damage supports faster learning. Our results suggest that motor noise slows reinforcement learning by impairing the mapping of reward to the correct action and that this may underlie deficits induced by cerebellar damage.},
	language = {en},
	number = {3},
	urldate = {2020-10-13},
	journal = {eneuro},
	author = {Therrien, Amanda S. and Wolpert, Daniel M. and Bastian, Amy J.},
	month = may,
	year = {2018},
	pages = {ENEURO.0050--18.2018},
	file = {Therrien et al_2018_Increasing Motor Noise Impairs Reinforcement Learning in Healthy Individuals.pdf:/Users/victorparedes/Zotero/storage/QMXU9SPR/Therrien et al_2018_Increasing Motor Noise Impairs Reinforcement Learning in Healthy Individuals.pdf:application/pdf}
}

@article{wolpert_principles_2011,
	title = {Principles of sensorimotor learning},
	volume = {12},
	issn = {1471-003X, 1471-0048},
	url = {http://www.nature.com/articles/nrn3112},
	doi = {10.1038/nrn3112},
	abstract = {The exploits of Martina Navratilova and Roger Federer represent the pinnacle of motor learning. However, when considering the range and complexity of the processes that are involved in motor learning, even the mere mortals among us exhibit abilities that are impressive. We exercise these abilities when taking up new activities — whether it is snowboarding or ballroom dancing — but also engage in substantial motor learning on a daily basis as we adapt to changes in our environment, manipulate new objects and refine existing skills. Here we review recent research in human motor learning with an emphasis on the computational mechanisms that are involved.},
	language = {en},
	number = {12},
	urldate = {2020-10-13},
	journal = {Nature Reviews Neuroscience},
	author = {Wolpert, Daniel M. and Diedrichsen, Jörn and Flanagan, J. Randall},
	month = dec,
	year = {2011},
	pages = {739--751},
	file = {Wolpert et al_2011_Principles of sensorimotor learning.pdf:/Users/victorparedes/Zotero/storage/5KDQ64MC/Wolpert et al_2011_Principles of sensorimotor learning.pdf:application/pdf}
}

@article{caramiaux_dissociable_2018,
	title = {Dissociable effects of practice variability on learning motor and timing skills},
	volume = {13},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0193580},
	doi = {10.1371/journal.pone.0193580},
	abstract = {Motor skill acquisition inherently depends on the way one practices the motor task. The amount of motor task variability during practice has been shown to foster transfer of the learned skill to other similar motor tasks. In addition, variability in a learning schedule, in which a task and its variations are interweaved during practice, has been shown to help the transfer of learning in motor skill acquisition. However, there is little evidence on how motor task variations and variability schedules during practice act on the acquisition of complex motor skills such as music performance, in which a performer learns both the right movements (motor skill) and the right time to perform them (timing skill). This study investigated the impact of rate (tempo) variability and the schedule of tempo change during practice on timing and motor skill acquisition. Complete novices, with no musical training, practiced a simple musical sequence on a piano keyboard at different rates. Each novice was assigned to one of four learning conditions designed to manipulate the amount of tempo variability across trials (large or small tempo set) and the schedule of tempo change (randomized or non-randomized order) during practice. At test, the novices performed the same musical sequence at a familiar tempo and at novel tempi (testing tempo transfer), as well as two novel (but related) sequences at a familiar tempo (testing spatial transfer). We found that practice conditions had little effect on learning and transfer performance of timing skill. Interestingly, practice conditions influenced motor skill learning (reduction of movement variability): lower temporal variability during practice facilitated transfer to new tempi and new sequences; non-randomized learning schedule improved transfer to new tempi and new sequences. Tempo (rate) and the sequence difficulty (spatial manipulation) affected performance variability in both timing and movement. These findings suggest that there is a dissociable effect of practice variability on learning complex skills that involve both motor and timing constraints.},
	language = {en},
	number = {3},
	urldate = {2020-10-13},
	journal = {PLOS ONE},
	author = {Caramiaux, Baptiste and Bevilacqua, Frédéric and Wanderley, Marcelo M. and Palmer, Caroline},
	editor = {Grahn, Jessica Adrienne},
	month = mar,
	year = {2018},
	pages = {e0193580},
	file = {Caramiaux et al_2018_Dissociable effects of practice variability on learning motor and timing skills.pdf:/Users/victorparedes/Zotero/storage/TKPKHH34/Caramiaux et al_2018_Dissociable effects of practice variability on learning motor and timing skills.pdf:application/pdf}
}

@article{sanchez_role_2017,
	title = {The role of motor variability in motor control and learning depends on the nature of the task and the individual’s capabilities},
	volume = {38},
	journal = {European Journal of Human Movement},
	author = {Sánchez, Carla Caballero and Moreno, Francisco Javier and Vaíllo, Raúl Reina and Romero, Alba Roldán and Coves, Álvaro and Murillo, David Barbado},
	year = {2017},
	pages = {12--26}
}

@article{dyer_advantages_2017,
	title = {Advantages of melodic over rhythmic movement sonification in bimanual motor skill learning},
	volume = {235},
	issn = {0014-4819, 1432-1106},
	url = {http://link.springer.com/10.1007/s00221-017-5047-8},
	doi = {10.1007/s00221-017-5047-8},
	language = {en},
	number = {10},
	urldate = {2020-10-13},
	journal = {Experimental Brain Research},
	author = {Dyer, J. F. and Stapleton, P. and Rodger, M. W. M.},
	month = oct,
	year = {2017},
	pages = {3129--3140},
	file = {Dyer et al_2017_Advantages of melodic over rhythmic movement sonification in bimanual motor.pdf:/Users/victorparedes/Zotero/storage/F2XV4V97/Dyer et al_2017_Advantages of melodic over rhythmic movement sonification in bimanual motor.pdf:application/pdf}
}

@article{sigrist_augmented_2013,
	title = {Augmented visual, auditory, haptic, and multimodal feedback in motor learning: {A} review},
	volume = {20},
	issn = {1069-9384, 1531-5320},
	shorttitle = {Augmented visual, auditory, haptic, and multimodal feedback in motor learning},
	url = {http://link.springer.com/10.3758/s13423-012-0333-8},
	doi = {10.3758/s13423-012-0333-8},
	abstract = {It is generally accepted that augmented feedback, provided by a human expert or a technical display, effectively enhances motor learning. However, discussion of the way to most effectively provide augmented feedback has been controversial. Related studies have focused primarily on simple or artificial tasks enhanced by visual feedback. Recently, technical advances have made it possible also to investigate more complex, realistic motor tasks and to implement not only visual, but also auditory, haptic, or multimodal augmented feedback. The aim of this review is to address the potential of augmented unimodal and multimodal feedback in the framework of motor learning theories. The review addresses the reasons for the different impacts of feedback strategies within or between the visual, auditory, and haptic modalities and the challenges that need to be overcome to provide appropriate feedback in these modalities, either in isolation or in combination. Accordingly, the design criteria for successful visual, auditory, haptic, and multimodal feedback are elaborated.},
	language = {en},
	number = {1},
	urldate = {2020-10-13},
	journal = {Psychonomic Bulletin \& Review},
	author = {Sigrist, Roland and Rauter, Georg and Riener, Robert and Wolf, Peter},
	month = feb,
	year = {2013},
	pages = {21--53},
	file = {Sigrist et al_2013_Augmented visual, auditory, haptic, and multimodal feedback in motor learning.pdf:/Users/victorparedes/Zotero/storage/RAKF3IWQ/Sigrist et al_2013_Augmented visual, auditory, haptic, and multimodal feedback in motor learning.pdf:application/pdf}
}

@article{bevilacqua_sensori-motor_2016,
	title = {Sensori-{Motor} {Learning} with {Movement} {Sonification}: {Perspectives} from {Recent} {Interdisciplinary} {Studies}},
	volume = {10},
	issn = {1662-453X},
	shorttitle = {Sensori-{Motor} {Learning} with {Movement} {Sonification}},
	url = {http://journal.frontiersin.org/Article/10.3389/fnins.2016.00385/abstract},
	doi = {10.3389/fnins.2016.00385},
	language = {en},
	urldate = {2020-10-13},
	journal = {Frontiers in Neuroscience},
	author = {Bevilacqua, Frédéric and Boyer, Eric O. and Françoise, Jules and Houix, Olivier and Susini, Patrick and Roby-Brami, Agnès and Hanneton, Sylvain},
	month = aug,
	year = {2016},
	file = {Bevilacqua et al_2016_Sensori-Motor Learning with Movement Sonification.pdf:/Users/victorparedes/Zotero/storage/LC7AYEW2/Bevilacqua et al_2016_Sensori-Motor Learning with Movement Sonification.pdf:application/pdf}
}

@inproceedings{anlauff_augmented_2013,
	address = {Philadelphia, PA, USA},
	title = {Augmented feedback for learning single-legged stance on a slackline},
	isbn = {978-1-4799-0774-8},
	url = {http://ieeexplore.ieee.org/document/6662104/},
	doi = {10.1109/ICVR.2013.6662104},
	abstract = {We present an auditory feedback system to assist learning the single-legged stance on a slackline, sensing the user’s posture with a Microsoft Kinect. Slacklining, or walking on an elevated length of tensioned webbing, has been associated with improved core strength, balance and concentration and may have applications for balance rehabilitation and research. Based on the considerable body of research on clinical balance training systems, we anticipate extending our system to support balance training in neurological patients and the elderly. As we hope our system will be based on inexpensive hardware suitable for inhome use, we discuss some of the shortcomings of this technology.},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {2013 {International} {Conference} on {Virtual} {Rehabilitation} ({ICVR})},
	publisher = {IEEE},
	author = {Anlauff, Jan and Cooperstock, Jeremy R. and Fung, Joyce},
	month = aug,
	year = {2013},
	pages = {162--163},
	file = {Anlauff et al_2013_Augmented feedback for learning single-legged stance on a slackline.pdf:/Users/victorparedes/Zotero/storage/36S2D35V/Anlauff et al_2013_Augmented feedback for learning single-legged stance on a slackline.pdf:application/pdf}
}

@article{schaffert_review_2019,
	title = {A {Review} on the {Relationship} {Between} {Sound} and {Movement} in {Sports} and {Rehabilitation}},
	volume = {10},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2019.00244/full},
	doi = {10.3389/fpsyg.2019.00244},
	abstract = {The role of auditory information on perceptual-motor processes has gained increased interest in sports and psychology research in recent years. Numerous neurobiological and behavioral studies have demonstrated the close interaction between auditory and motor areas of the brain, and the importance of auditory information for movement execution, control, and learning. In applied research, artiﬁcially produced acoustic information and real-time auditory information have been implemented in sports and rehabilitation to improve motor performance in athletes, healthy individuals, and patients affected by neurological or movement disorders. However, this research is scattered both across time and scientiﬁc disciplines. The aim of this paper is to provide an overview about the interaction between movement and sound and review the current literature regarding the effect of natural movement sounds, movement soniﬁcation, and rhythmic auditory information in sports and motor rehabilitation. The focus here is threefold: ﬁrstly, we provide an overview of empirical studies using natural movement sounds and movement soniﬁcation in sports. Secondly, we review recent clinical and applied studies using rhythmic auditory information and soniﬁcation in rehabilitation, addressing in particular studies on Parkinson’s disease and stroke. Thirdly, we summarize current evidence regarding the cognitive mechanisms and neural correlates underlying the processing of auditory information during movement execution and its mental representation. The current state of knowledge here reviewed provides evidence of the feasibility and effectiveness of the application of auditory information to improve movement execution, control, and (re)learning in sports and motor rehabilitation. Findings also corroborate the critical role of auditory information in auditory-motor coupling during motor (re)learning and performance, suggesting that this area of clinical and applied research has a large potential that is yet to be fully explored.},
	language = {en},
	urldate = {2020-10-13},
	journal = {Frontiers in Psychology},
	author = {Schaffert, Nina and Janzen, Thenille Braun and Mattes, Klaus and Thaut, Michael H.},
	month = feb,
	year = {2019},
	pages = {244},
	file = {Schaffert et al_2019_A Review on the Relationship Between Sound and Movement in Sports and.pdf:/Users/victorparedes/Zotero/storage/TJLHD7VK/Schaffert et al_2019_A Review on the Relationship Between Sound and Movement in Sports and.pdf:application/pdf}
}

@inproceedings{ramsay_body_2020,
	address = {Snowmass Village, CO, USA},
	title = {Body {Pose} {Sonification} for a {View}-{Independent} {Auditory} {Aid} to {Blind} {Rock} {Climbers}},
	isbn = {978-1-72816-553-0},
	url = {https://ieeexplore.ieee.org/document/9093462/},
	doi = {10.1109/WACV45572.2020.9093462},
	abstract = {Rock climbing is a sport in which blind people have traditionally found it extremely difﬁcult to excel due to the high degree of visual problem solving required, and also the requirement to climb with a sighted assistant. We present a system which automates the role of the sighted assistant in order to provide blind people with the freedom to climb and train on their own. We address climbing-speciﬁc limitations of a state-of-the-art skeleton tracking system, and discuss the ways in which we mitigated these limitations using postprocessing techniques tuned specially for a climbing scenario. We also describe the auditory feedback system used to instruct the blind climber, and demonstrate that a user can learn to follow it in a relatively short time by showing a signiﬁcant improvement in performance over just a few trials with the system.},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {2020 {IEEE} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	publisher = {IEEE},
	author = {Ramsay, Joseph and Chang, Hyung Jin},
	month = mar,
	year = {2020},
	pages = {3403--3410},
	file = {Ramsay_Chang_2020_Body Pose Sonification for a View-Independent Auditory Aid to Blind Rock.pdf:/Users/victorparedes/Zotero/storage/URPI66FP/Ramsay_Chang_2020_Body Pose Sonification for a View-Independent Auditory Aid to Blind Rock.pdf:application/pdf}
}

@inproceedings{bevilacqua_exploring_2018,
	address = {Genoa Italy},
	title = {Exploring different movement sonification strategies for rehabilitation in clinical settings},
	isbn = {978-1-4503-6504-8},
	url = {https://dl.acm.org/doi/10.1145/3212721.3212881},
	doi = {10.1145/3212721.3212881},
	abstract = {We describe an interactive system that allows for sonifying arm movements. The aim is to support stroke patients going through rehabilitation by providing them with augmented auditory feedback that reacts to their movements. The system is based on IMU sensors (Inertial Measurements Unit) attached to each arm. The movement data are streamed in real-time to a laptop computer that generates various sounds or musical interactions using a program we developed. We tested different types of auditory feedback, each of them using a specific strategy for the sound-movement mapping. The first type of movement-sound mappings is based on direct relationships between the reaching distance and either the pitch of a continuous tone, or the tempo of a regular beat pattern. The second type of mapping is music-oriented: the user movement allows for controlling the tempo of musical pieces. The third type of mapping associates the hand position to specific environmental sounds. We report here on the technical system along with preliminary results in a clinical setting with both post-stroke patients and healthy users.},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Movement} and {Computing}},
	publisher = {ACM},
	author = {Bevilacqua, Frédéric and Segalen, Maël and Marchand-Pauvert, Véronique and Peyre, Iseline and Pradat-Diehl, Pascale and Roby-Brami, Agnès},
	month = jun,
	year = {2018},
	pages = {1--6},
	file = {Bevilacqua et al_2018_Exploring different movement sonification strategies for rehabilitation in.pdf:/Users/victorparedes/Zotero/storage/CETZ7WRC/Bevilacqua et al_2018_Exploring different movement sonification strategies for rehabilitation in.pdf:application/pdf}
}

@inproceedings{avissar_audio_2013,
	title = {An audio game app using interactive movement sonification for targeted posture control},
	booktitle = {Audio {Engineering} {Society} {Convention} 135},
	publisher = {Audio Engineering Society},
	author = {Avissar, Daniel and Leider, Colby N and Bennett, Christopher and Gailey, Robert},
	year = {2013}
}

@inproceedings{yang_sonic_2013,
	title = {Sonic trainer: real-time sonification of muscular activity and limb positions in general physical exercise},
	booktitle = {Proceedings of the {ISon} 2013, 4th {Interactive} {Sonification} {Workshop}},
	author = {Yang, Jiajun and Hunt, Andy},
	year = {2013},
	pages = {44--51}
}

@inproceedings{fyans_ecological_2012,
	address = {Ann Arbor, Michigan},
	title = {Ecological considerations for participatory design of {DMIs}},
	url = {http://www.nime.org/proceedings/2012/nime2012_253.pdf},
	doi = {10.5281/zenodo.1178257},
	abstract = {A study is presented examining the participatory design of digital musical interactions. The study takes into consideration the entire ecology of digital musical interactions including the designer, performer and spectator. A new instrument is developed through iterative participatory design involving a group of performers. Across the study the evolution of creative practice and skill development in an emerging community of practice is examined and a spectator study addresses the cognition of performance and the perception of skill with the instrument. Observations are presented regarding the cognition of a novel interaction and evolving notions of skill. The design process of digital musical interactions is reflected on focusing on involvement of the spectator in design contexts.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {University of Michigan},
	author = {Fyans, A. Cavan and Marquez-Borbon, Adnan and Stapleton, Paul and Gurevich, Michael},
	year = {2012},
	note = {ISSN: 2220-4806},
	keywords = {cognition, DMIs, participatory design, skill, spectator}
}

@inproceedings{zappi_dimensionality_2014,
	address = {London, United Kingdom},
	title = {Dimensionality and {Appropriation} in {Digital} {Musical} {Instrument} {Design}},
	url = {http://www.nime.org/proceedings/2014/nime2014_409.pdf},
	doi = {10.5281/zenodo.1178993},
	abstract = {This paper investigates the process of appropriation in digital musical instrument performance, examining the effect of instrument complexity on the emergence of personal playing styles. Ten musicians of varying background were given a deliberately constrained musical instrument, a wooden cube containing a touch/force sensor, speaker and embedded computer. Each cube was identical in construction, but half the instruments were configured for two degrees of freedom while the other half allowed only a single degree. Each musician practiced at home and presented two performances, in which their techniques and reactions were assessed through video, sensor data logs, questionnaires and interviews. Results show that the addition of a second degree of freedom had the counterintuitive effect of reducing the exploration of the instrument's affordances; this suggested the presence of a dominant constraint in one of the two configurations which strongly differentiated the process of appropriation across the two groups of participants.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Goldsmiths, University of London},
	author = {Zappi, Victor and McPherson, Andrew},
	month = jun,
	year = {2014},
	note = {ISSN: 2220-4806},
	pages = {455--460}
}

@inproceedings{tom_rebuilding_2019,
	address = {Porto Alegre, Brazil},
	title = {Rebuilding and {Reinterpreting} a {Digital} {Musical} {Instrument} — {The} {Sponge}},
	url = {http://www.nime.org/proceedings/2019/nime2019_paper008.pdf},
	doi = {10.5281/zenodo.3672858},
	abstract = {Although several Digital Musical Instruments (DMIs) have been presented at NIME, very few of them remain accessible to the community. Rebuilding a DMI is often a necessary step to allow for performance with NIMEs. Rebuilding a DMI exactly similar to its original, however, might not be possible due to technology obsolescence, lack of documentation or other reasons. It might then be interesting to re-interpret a DMI and build an instrument inspired by the original one, creating novel performance opportunities. This paper presents the challenges and approaches involved in rebuilding and re-interpreting an existing DMI, The Sponge by Martin Marier. The rebuilt versions make use of newer/improved technology and customized design aspects like addition of vibrotactile feedback and implementation of different mapping strategies. It also discusses the implications of embedding sound synthesis within the DMI, by using the Prynth framework and further presents a comparison between this approach and the more traditional ground-up approach. As a result of the evaluation and comparison of the two rebuilt DMIs, we present a third version which combines the benefits and discuss performance issues with these devices.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {UFRGS},
	author = {Tom, Ajin Jiji and Venkatesan, Harish Jayanth and Franco, Ivan and Wanderley, Marcelo},
	editor = {Queiroz, Marcelo and Sedó, Anna Xambó},
	month = jun,
	year = {2019},
	note = {ISSN: 2220-4806},
	pages = {37--42}
}

@inproceedings{gold_playing_2020,
	address = {Birmingham, UK},
	title = {P(l)aying {Attention}: {Multi}-modal, multi-temporal music control},
	url = {https://www.nime.org/proceedings/2020/nime2020_paper33.pdf},
	abstract = {The expressive control of sound and music through body movements is well-studied. For some people, body movement is demanding, and although they would prefer to express themselves freely using gestural control, they are unable to use such interfaces without difficulty. In this paper, we present the P(l)aying Attention framework for manipulating recorded music to support these people, and to help the therapists that work with them. The aim is to facilitate body awareness, exploration, and expressivity by allowing the manipulation of a pre-recorded ‘ensemble’ through an interpretation of body movement, provided by a machine-learning system trained on physiotherapist assessments and movement data from people with chronic pain. The system considers the nature of a person’s movement (e.g. protective) and offers an interpretation in terms of the joint-groups that are playing a major role in the determination at that point in the movement, and to which attention should perhaps be given (or the opposite at the user’s discretion). Using music to convey the interpretation offers informational (through movement sonification) and creative (through manipulating the ensemble by movement) possibilities. The approach offers the opportunity to explore movement and music at multiple timescales and under varying musical aesthetics.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Birmingham City University},
	author = {Gold, Nicolas E and Wang, Chongyang and Olugbade, Temitayo and Berthouze, Nadia and Williams, Amanda},
	editor = {Michon, Romain and Schroeder, Franziska},
	month = jul,
	year = {2020},
	note = {ISSN: 2220-4806},
	pages = {172--175}
}

@inproceedings{fiebrink_reflections_2020,
	address = {Birmingham, UK},
	title = {Reflections on {Eight} {Years} of {Instrument} {Creation} with {Machine} {Learning}},
	url = {https://www.nime.org/proceedings/2020/nime2020_paper45.pdf},
	abstract = {Machine learning (ML) has been used to create mappings for digital musical instruments for over twenty-five years, and numerous ML toolkits have been developed for the NIME community. However, little published work has studied how ML has been used in sustained instrument building and performance practices. This paper examines the experiences of instrument builder and performer Laetitia Sonami, who has been using ML to build and refine her Spring Spyre instrument since 2012. Using Sonami’s current practice as a case study, this paper explores the utility, opportunities, and challenges involved in using ML in practice over many years. This paper also reports the perspective of Rebecca Fiebrink, the creator of the Wekinator ML tool used by Sonami, revealing how her work with Sonami has led to changes to the software and to her teaching. This paper thus contributes a deeper understanding of the value of ML for NIME practitioners, and it can inform design considerations for future ML toolkits as well as NIME pedagogy. Further, it provides new perspectives on familiar NIME conversations about mapping strategies, expressivity, and control, informed by a dedicated practice over many years.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Birmingham City University},
	author = {Fiebrink, Rebecca and Sonami, Laetitia},
	editor = {Michon, Romain and Schroeder, Franziska},
	month = jul,
	year = {2020},
	note = {ISSN: 2220-4806},
	pages = {237--242}
}

@inproceedings{desmith_squishboi_2020,
	address = {Birmingham, UK},
	title = {{SQUISHBOI}: {A} {Multidimensional} {Controller} for {Complex} {Musical} {Interactions} using {Machine} {Learning}},
	url = {https://www.nime.org/proceedings/2020/nime2020_paper68.pdf},
	abstract = {We present SQUISHBOI, a continuous touch controller for interacting with complex musical systems. An elastic rubber membrane forms the playing surface of the instrument, while machine learning is used for dimensionality reduction and gesture recognition. The membrane is stretched over a hollow shell which permits considerable depth excursion, with an array of distance sensors tracking the surface displacement from underneath. The inherent dynamics of the membrane lead to cross-coupling between nearby sensors, however we do not see this as a flaw or limitation. Instead we find this coupling gives structure to the playing techniques and mapping schemes chosen by the user. The instrument is best utilized as a tool for actively designing abstraction and forming a relative control structure within a given system, one which allows for intuitive gestural control beyond what can be accomplished with conventional musical controllers.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Birmingham City University},
	author = {DeSmith, Marcel O and Piepenbrink, Andrew and Kapur, Ajay},
	editor = {Michon, Romain and Schroeder, Franziska},
	month = jul,
	year = {2020},
	note = {ISSN: 2220-4806},
	pages = {353--356}
}

@inproceedings{brizolara_elemental_2020,
	address = {Birmingham, UK},
	title = {Elemental: a {Gesturally} {Controlled} {System} to {Perform} {Meteorological} {Sounds}},
	url = {https://www.nime.org/proceedings/2020/nime2020_paper90.pdf},
	abstract = {In this paper, we present and evaluate Elemental, a NIME (New Interface for Musical Expression) based on audio synthesis of sounds of meteorological phenomena, namely rain, wind and thunder, intended for application in contemporary music/sound art, performing arts and entertainment. We first describe the system, controlled by the performer’s arms through Inertial Measuring Units and Electromyography sensors. The produced data is analyzed and used through mapping strategies as input of the sound synthesis engine. We conducted user studies to refine the sound synthesis engine, the choice of gestures and the mappings between them, and to finally evaluate this proof of concept. Indeed, the users approached the system with their own awareness ranging from the manipulation of abstract sound to the direct simulation of atmospheric phenomena - in the latter case, it could even be to revive memories or to create novel situations. This suggests that the approach of instrumentalization of sounds of known source may be a fruitful strategy for constructing expressive interactive sonic systems.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Birmingham City University},
	author = {Brizolara, Tiago and Gibet, Sylvie and Larboulette, Caroline},
	editor = {Michon, Romain and Schroeder, Franziska},
	month = jul,
	year = {2020},
	note = {ISSN: 2220-4806},
	pages = {470--476}
}

@book{green_how_2002,
	address = {Aldershot, Hants ; Burlington, VT},
	series = {Ashgate popular and folk music series},
	title = {How popular musicians learn: a way ahead for music education},
	isbn = {978-0-7546-0338-2 978-0-7546-3226-9},
	shorttitle = {How popular musicians learn},
	language = {en},
	publisher = {Ashgate},
	author = {Green, Lucy},
	year = {2002},
	keywords = {England, Instruction and study, Music, Popular music},
	file = {Green_2002_How popular musicians learn.pdf:/Users/victorparedes/Zotero/storage/BZVMUWJV/Green_2002_How popular musicians learn.pdf:application/pdf}
}

@article{schiavio_instrumental_2019,
	title = {Instrumental {Technique}, {Expressivity}, and {Communication}. {A} {Qualitative} {Study} on {Learning} {Music} in {Individual} and {Collective} {Settings}},
	volume = {10},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2019.00737/full},
	doi = {10.3389/fpsyg.2019.00737},
	abstract = {In this paper, we present a qualitative study comparing individual and collective music pedagogies from the point of view of the learner. In doing so, we discuss how the theoretical tools of embodied cognitive science (ECS) can provide adequate resources to capture the main properties of both contexts. We begin by outlining the core principles of ECS, describing how it emerged in response to the information-processing approach to mind, which dominated the cognitive sciences for the latter half of the 20th century. We then consider the orientation offered by ECS and its relevance for music education. We do this by identifying overlapping principles between three tenets of ECS, and three aspects of pedagogical practice. This results in the categories of “instrumental technique,” “expressivity,” and “communication,” which we adopted to examine and categorize the data emerging from our study. In conclusion, we consider the results of our study in light of ECS, discussing what implications can emerge for concrete pedagogical practices in both individual and collective settings.},
	language = {en},
	urldate = {2020-10-13},
	journal = {Frontiers in Psychology},
	author = {Schiavio, Andrea and van der Schyff, Dylan and Biasutti, Michele and Moran, Nikki and Parncutt, Richard},
	month = apr,
	year = {2019},
	pages = {737},
	file = {Schiavio et al_2019_Instrumental Technique, Expressivity, and Communication.pdf:/Users/victorparedes/Zotero/storage/MJRXVNDX/Schiavio et al_2019_Instrumental Technique, Expressivity, and Communication.pdf:application/pdf}
}

@article{luce_collaborative_2001,
	title = {Collaborative {Learning} in {Music} {Education}: {A} {Review} of the {Literature}},
	volume = {19},
	issn = {8755-1233, 1945-0109},
	shorttitle = {Collaborative {Learning} in {Music} {Education}},
	url = {http://journals.sagepub.com/doi/10.1177/87551233010190020105},
	doi = {10.1177/87551233010190020105},
	abstract = {Keil, 1987) that related to collaborative learning as discussed in this paper. In the search result’s single Arts and Humanities Index citation, Germer (1996) pleaded for collaborative learning in bibliographic education to “encourage students to embrace the library with their mentors” (p. 759). While there were nine dissertations identified in the search, none met the inclusionary criteria. Berg (1997) and Kieffer (1996) considered knowledge within a socially constructed context, yet it was only among students. Davidson and Scripp (1990) discussed reflective thinking and effective student-conductor interactions in an Arts Propel cooperative, rather than a collaborative learning project.},
	language = {en},
	number = {2},
	urldate = {2020-10-13},
	journal = {Update: Applications of Research in Music Education},
	author = {Luce, David W.},
	month = mar,
	year = {2001},
	pages = {20--25},
	file = {Luce_2001_Collaborative Learning in Music Education.pdf:/Users/victorparedes/Zotero/storage/H5JJ3LMY/Luce_2001_Collaborative Learning in Music Education.pdf:application/pdf}
}

@article{bjontegaard_combination_2015,
	title = {A combination of one-to-one teaching and small group teaching in higher music education in {Norway} – a good model for teaching?},
	volume = {32},
	issn = {0265-0517, 1469-2104},
	url = {https://www.cambridge.org/core/product/identifier/S026505171400014X/type/journal_article},
	doi = {10.1017/S026505171400014X},
	abstract = {Instrumental teachers in higher music education in Norway and elsewhere traditionally organise their teaching as individual lessons with one teacher and one student. This paper takes a closer look at how a horn teacher at the Norwegian Academy of Music has organised her weekly teaching in individual, small group and master class lessons with all her students. The project being described in the paper has since been extended to other instruments, but this paper concentrates on the horn model. The main focus is on small group lessons where the students themselves play and comment on fellow students’ performances. The evidence suggests that a combination of teaching in individual, small group and master class lessons is the best way of educating students as responsible, reflective and professional musicians.},
	language = {en},
	number = {1},
	urldate = {2020-10-13},
	journal = {British Journal of Music Education},
	author = {Bjøntegaard, Bjørg Julsrud},
	month = mar,
	year = {2015},
	pages = {23--36},
	file = {Bjøntegaard_2015_A combination of one-to-one teaching and small group teaching in higher music.pdf:/Users/victorparedes/Zotero/storage/3PAXPMFE/Bjøntegaard_2015_A combination of one-to-one teaching and small group teaching in higher music.pdf:application/pdf}
}

@inproceedings{marquez-borbon_problem_2018,
	address = {Blacksburg, Virginia, USA},
	title = {The {Problem} of {DMI} {Adoption} and {Longevity}: {Envisioning} a {NIME} {Performance} {Pedagogy}},
	isbn = {978-1-949373-99-8},
	url = {http://www.nime.org/proceedings/2018/nime2018_paper0040.pdf},
	doi = {10.5281/zenodo.1302541},
	abstract = {This paper addresses the prevailing longevity problem of digital musical instruments (DMIs) in NIME research and design by proposing a holistic system design approach. Despite recent efforts to examine the main contributing factors of DMI falling into obsolescence, such attempts to remedy this issue largely place focus on the artifacts establishing themselves, their design processes and technologies. However, few existing studies have attempted to proactively build a community around technological platforms for DMIs, whilst bearing in mind the social dynamics and activities necessary for a budding community. We observe that such attempts while important in their undertaking, are limited in their scope. In this paper we will discuss that achieving some sort of longevity must be addressed beyond the device itself and must tackle broader ecosystemic factors. We hypothesize, that a longevous DMI design must not only take into account a target community but it may also require a non-traditional pedagogical system that sustains artistic practice.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Virginia Tech},
	author = {Marquez-Borbon, Adnan and Martinez-Avila, Juan Pablo},
	editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
	month = jun,
	year = {2018},
	note = {ISSN: 2220-4806},
	pages = {190--195}
}

@inproceedings{marquez-borbon_collaborative_2020,
	address = {Birmingham, UK},
	title = {Collaborative {Learning} with {Interactive} {Music} {Systems}},
	url = {https://www.nime.org/proceedings/2020/nime2020_paper113.pdf},
	abstract = {This paper presents the results of an observational study focusing on the collaborative learning processes of a group of performers with an interactive musical system. The main goal of this study was to implement methods for learning and developing practice with these technological objects in order to generate future pedagogical methods. During the research period of six months, four participants regularly engaged in workshop-type scenarios where learning objectives were proposed and guided by themselves.The principal researcher, working as participant-observer, did not impose or prescribed learning objectives to the other members of the group. Rather, all participants had equal say in what was to be done and how it was to be accomplished. Results show that the group learning environment is rich in opportunities for learning, mutual teaching, and for establishing a comunal practice for a given interactive musical system.Key findings suggest that learning by demonstration, observation and modelling are significant for learning in this context. Additionally, it was observed that a dialogue and a continuous flow of information between the members of the community is needed in order to motivate and further their learning.},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	publisher = {Birmingham City University},
	author = {Marquez-Borbon, Adnan},
	editor = {Michon, Romain and Schroeder, Franziska},
	month = jul,
	year = {2020},
	note = {ISSN: 2220-4806},
	pages = {581--586}
}

@book{gaunt_collaborative_2016,
	title = {Collaborative learning in higher music education},
	publisher = {Routledge},
	author = {Gaunt, Helena and Westerlund, Heidi},
	year = {2016}
}

@inproceedings{gullberg_boom_2006,
	title = {Boom town music education: a co-creating way to learn music within formal music education},
	booktitle = {International {Conference} on {Music} {Perception} and {Cognition}: 22/08/2006-26/08/2006},
	publisher = {Society for Music Perception},
	author = {Gullberg, Anna-Karin},
	year = {2006},
	pages = {1622--1627}
}

@incollection{lesaffre_designing_2017,
	address = {New York ; London : Routledge, 2017.},
	edition = {1},
	title = {Designing {Action}–{Sound} {Metaphors} {Using} {Motion} {Sensing} and {Descriptor}-{Based} {Synthesis} of {Recorded} {Sound} {Materials}},
	isbn = {978-1-315-62136-4},
	url = {https://www.taylorfrancis.com/books/9781317219736/chapters/10.4324/9781315621364-43},
	abstract = {In this chapter, we present a general methodology for designing interactive musical systems, using movement sensing and descriptor-based synthesis of recorded sound materials. Importantly, the design principles focus on action–sound metaphors that can be built upon audio features of recorded sound materials and their possible relationships to human movement. We describe the critical design choices, including sensing technologies, movement analysis, and action–sound models, along with application examples.},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {The {Routledge} {Companion} to {Embodied} {Music} {Interaction}},
	publisher = {Routledge},
	author = {Bevilacqua, Frédéric and Schnell, Norbert and Françoise, Jules and Boyer, Éric O. and Schwarz, Diemo and Caramiaux, Baptiste},
	editor = {Lesaffre, Micheline and Maes, Pieter-Jan and Leman, Marc},
	month = sep,
	year = {2017},
	doi = {10.4324/9781315621364-43},
	pages = {391--401},
	file = {Bevilacqua et al_2017_Designing Action–Sound Metaphors Using Motion Sensing and Descriptor-Based.pdf:/Users/victorparedes/Zotero/storage/4RVH695N/Bevilacqua et al_2017_Designing Action–Sound Metaphors Using Motion Sensing and Descriptor-Based.pdf:application/pdf}
}

@book{gaggioli_human_2015,
	address = {Warsaw, Poland},
	title = {Human {Computer} {Confluence}: {Transforming} {Human} {Experience} {Through} {Symbiotic} {Technologies}},
	isbn = {978-3-11-047113-7},
	shorttitle = {Human {Computer} {Confluence}},
	url = {http://www.degruyter.com/view/books/9783110471137/9783110471137/9783110471137.xml},
	abstract = {In this chapter, we review research that was conducted at Ircam in the Real-Time Musical Interactions team on motion-based musical interactions. First, we developed various tangible motion-sensing interfaces and interactive sound synthesis systems. Second, we explored different approaches to design motion-sound relationships, which can be derived from object affordances, metaphors or from embodied listening explorations. Certain scenarios utilize machine-learning techniques we shortly describe. Finally, some examples of collaborative musical interactions are presented, which represents an important area of development with the rapidly increased capabilities of embedded and mobile computing. We argue that the research we report relates to challenges posed by the Human Computer Confluence research agenda.},
	language = {en},
	urldate = {2020-10-13},
	publisher = {De Gruyter Open},
	author = {Gaggioli, Andrea and Ferscha, Alois and Riva, Giuseppe and Dunne, Stephen and Viaud-Delmon, Isabelle},
	month = jan,
	year = {2015},
	doi = {10.1515/9783110471137},
	file = {Gaggioli et al_2015_Human Computer Confluence.pdf:/Users/victorparedes/Zotero/storage/VBKF8XTM/Gaggioli et al_2015_Human Computer Confluence.pdf:application/pdf}
}

@inproceedings{francoise_soundguides_2016,
	address = {San Jose, California, USA},
	title = {{SoundGuides}: {Adapting} {Continuous} {Auditory} {Feedback} to {Users}},
	isbn = {978-1-4503-4082-3},
	shorttitle = {{SoundGuides}},
	url = {http://dl.acm.org/citation.cfm?doid=2851581.2892420},
	doi = {10.1145/2851581.2892420},
	abstract = {We introduce SoundGuides, a user adaptable tool for auditory feedback on movement. The system is based on a interactive machine learning approach, where both gestures and sounds are ﬁrst conjointly designed and conjointly learned by the system. The system can then automatically adapt the auditory feedback to any new user, taking into account the particular way each user performs a given gesture. SoundGuides is suitable for the design of continuous auditory feedback aimed at guiding users’ movements and helping them to perform a speciﬁc movement consistently over time. Applications span from movement-based interaction techniques to auditory-guided rehabilitation. We ﬁrst describe our system and report a study that demonstrates a ‘stabilizing effect’ of our adaptive auditory feedback method.},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}  - {CHI} {EA} '16},
	publisher = {ACM Press},
	author = {Françoise, Jules and Chapuis, Olivier and Hanneton, Sylvain and Bevilacqua, Frédéric},
	year = {2016},
	pages = {2829--2836},
	file = {Françoise et al_2016_SoundGuides.pdf:/Users/victorparedes/Zotero/storage/G6SA6UH3/Françoise et al_2016_SoundGuides.pdf:application/pdf}
}

@inproceedings{rasamimanana_modular_2011,
	address = {Funchal, Portugal},
	title = {Modular musical objects towards embodied control of digital music},
	isbn = {978-1-4503-0478-8},
	url = {http://portal.acm.org/citation.cfm?doid=1935701.1935704},
	doi = {10.1145/1935701.1935704},
	abstract = {We present an ensemble of tangible objects and software modules designed for musical interaction and performance. The tangible interfaces form an ensemble of connected objects communicating wirelessly. A central concept is to let users determine the ﬁnal musical function of the objects, favoring customization, assembling, repurposing. This might imply assembling the wireless interfaces with existing everyday objects or musical instruments. Moreover, gesture analysis and recognition modules allow the users to deﬁne their own action/motion for the control of sound parameters. Various sound engines and interaction scenarios were built and experimented. Some examples that were developed in a music pedagogy context are described.},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {Proceedings of the fifth international conference on {Tangible}, embedded, and embodied interaction - {TEI} '11},
	publisher = {ACM Press},
	author = {Rasamimanana, Nicolas and Bevilacqua, Frederic and Schnell, Norbert and Guedy, Fabrice and Flety, Emmanuel and Maestracci, Come and Zamborlin, Bruno and Frechin, Jean-Louis and Petrevski, Uros},
	year = {2011},
	pages = {9},
	file = {Rasamimanana et al_2011_Modular musical objects towards embodied control of digital music.pdf:/Users/victorparedes/Zotero/storage/3DVB6VFA/Rasamimanana et al_2011_Modular musical objects towards embodied control of digital music.pdf:application/pdf}
}

@inproceedings{bevilacqua_-mo_2013,
	address = {Paris, France},
	title = {De-{Mo}: designing action-sound relationships with the mo interfaces},
	isbn = {978-1-4503-1952-2},
	shorttitle = {De-{Mo}},
	url = {http://dl.acm.org/citation.cfm?doid=2468356.2479571},
	doi = {10.1145/2468356.2479571},
	abstract = {The Modular Musical Objects (MO) are an ensemble of tangible interfaces and software modules for creating novel musical instruments or for augmenting objects with sound. In particular, the MOs allow for designing action-sound relationships and behaviors based on the interaction with tangible objects or free body movements. Such interaction scenarios can be inspired by the aﬀordances of particular objects (e.g. a ball, a table), by interaction metaphors based on the playing techniques of musical instruments or games. We describe speciﬁc examples of action-sound relationships that are made possible by the MO software modules and which take advantage of machine learning techniques.},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {{CHI} '13 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems} on - {CHI} {EA} '13},
	publisher = {ACM Press},
	author = {Bevilacqua, Frédéric and Schnell, Norbert and Rasamimanana, Nicolas and Bloit, Julien and Flety, Emmanuel and Caramiaux, Baptiste and Françoise, Jules and Boyer, Eric},
	year = {2013},
	pages = {2907},
	file = {Bevilacqua et al_2013_De-Mo.pdf:/Users/victorparedes/Zotero/storage/M7V7CN65/Bevilacqua et al_2013_De-Mo.pdf:application/pdf}
}

@inproceedings{schwarz_real-time_2006,
	title = {Real-{Time} {Corpus}-{Based} {Concatenative} {Synthesis} with {CataRT}},
	booktitle = {{IN} {PROC}. {OF} {THE} {INT}. {CONF}. {ON} {DIGITAL} {AUDIO} {EFFECTS} ({DAFX}-06},
	author = {Schwarz, Diemo and Beller, Grégory and Verbrugghe, Bruno and Britton, Sam},
	year = {2006},
	pages = {279--282}
}

@article{francoise_motion-sound_2018,
	title = {Motion-{Sound} {Mapping} through {Interaction}: {An} {Approach} to {User}-{Centered} {Design} of {Auditory} {Feedback} {Using} {Machine} {Learning}},
	volume = {8},
	issn = {2160-6455, 2160-6463},
	shorttitle = {Motion-{Sound} {Mapping} through {Interaction}},
	url = {https://dl.acm.org/doi/10.1145/3211826},
	doi = {10.1145/3211826},
	language = {en},
	number = {2},
	urldate = {2020-10-31},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Françoise, Jules and Bevilacqua, Frédéric},
	month = jul,
	year = {2018},
	pages = {1--30},
	file = {Françoise et Bevilacqua - 2018 - Motion-Sound Mapping through Interaction An Appro.pdf:/Users/victorparedes/Zotero/storage/ET6BEHPH/Françoise et Bevilacqua - 2018 - Motion-Sound Mapping through Interaction An Appro.pdf:application/pdf}
}
